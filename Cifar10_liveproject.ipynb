{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10_liveproject.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyOqs3JAUuJWnzW60sNZOn2F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timgluz/colab_notebooks/blob/master/Cifar10_liveproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hTPEcVoeDBE",
        "colab_type": "text"
      },
      "source": [
        "# Loading Dataset\n",
        "\n",
        "Keras provides the CIFAR dataset for us to load using load_data() method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnYYsF6eeBhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        " \n",
        "# load the pre-shuffled train and test data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        " \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        "fig = plt.figure(figsize=(20,5))\n",
        "for i in range(36):\n",
        "    ax = fig.add_subplot(3, 12, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(x_train[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z99Eqnv7eP-w",
        "colab_type": "text"
      },
      "source": [
        "# Image preprocessing\n",
        "\n",
        "**TIP** When using gradient descent, you should ensure that all features have a similar scale or else it will take much longer to converge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-HRHwZSeQRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rescale images by dividing the pixel values by 255 [0,255] --> [0,1]\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjbwWI5ge4aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# break training set into training and validation sets\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        " \n",
        "# print shape of training set\n",
        "print('x_train shape:', x_train.shape)\n",
        " \n",
        "# print number of training, validation, and test images\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print(x_valid.shape[0], 'validation samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPaShTVjfIys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        " \n",
        "# one-hot encode the labels\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHD0vgxPq-oQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize also y_valid\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St1cG5qhfWiY",
        "colab_type": "text"
      },
      "source": [
        "# Building a model\n",
        "\n",
        "The network consists of three CONV and POOL layers + 2 FC layers (also called dense). Note that we will use the RELU activation function for all the hidden layers. In the last dense layer we will use a Softmax activation function with 10 nodes to return an array of 10 probability scores (summing to 1). Each score will be the probability that the current image belong to our 10 image classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zUqRbP_ftDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "\n",
        "  # layer.1 - specifying the input shape\n",
        "  Conv2D(filters = 16, kernel_size = 2, padding = 'same', activation = 'relu',\n",
        "        input_shape = (32, 32, 3)),\n",
        "  MaxPooling2D(pool_size = 2),\n",
        "\n",
        "  # layer.2\n",
        "  Conv2D(filters = 32, kernel_size = 2, padding = 'same', activation = 'relu'),\n",
        "  MaxPooling2D(pool_size = 2),\n",
        "\n",
        "  # layer.3\n",
        "  Conv2D(filters = 64, kernel_size = 2, padding = 'same', activation = 'relu'),\n",
        "  MaxPooling2D(pool_size = 2),\n",
        "\n",
        "  # layer.4 - dropout layer to avoid overfitting with 30% rate\n",
        "  Dropout(0.3),\n",
        "\n",
        "  # flatten the last feature map into a vector of features\n",
        "  Flatten(),\n",
        "\n",
        "  # add the first FullyConnected layer\n",
        "  Dense(500, activation = 'relu'),\n",
        "  Dropout(0.4),\n",
        "\n",
        "  # final layer\n",
        "  Dense(num_classes, activation = 'softmax')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_MtFDSHh0t0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "# momentum optimizer gives accuracy 73%\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "optimizer2 = keras.optimizers.RMSprop(lr = 0.0001, rho = 0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer2, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg-RgUtRjgjY",
        "colab_type": "text"
      },
      "source": [
        "# Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_O8Ixatje_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint  \n",
        " \n",
        " \n",
        "# train the model\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
        " \n",
        "hist = model.fit(x_train, y_train, batch_size=32, \n",
        "                 epochs=100,\n",
        "                 validation_data=(x_valid, y_valid), \n",
        "                 callbacks=[checkpointer], \n",
        "                 verbose=2, \n",
        "                 shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YINZI26qtSoI",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate the model\n",
        "\n",
        "The last step is to evaluate our model and calculate the accuracy value in percentage of how many times our model is correct in predicting the image classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOectwKdtPjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the weights that yielded the best validation accuracy\n",
        "model.load_weights('model.weights.best.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp7BCq7TtUHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate and print test accuracy\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}